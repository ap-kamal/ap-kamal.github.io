{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adjustable-double",
   "metadata": {},
   "source": [
    "# Part 1 - Predicting Review Scores on Pitchfork\n",
    "\n",
    "For Part 1, we will be using data from [this paper](https://ojs.aaai.org/index.php/ICWSM/article/view/7355). The data is a collection of reviews from [Pitchfork](https://pitchfork.com/), a site that provides expert reviews of music album. The authors of this paper have also combined the data with a set of features from [Spotify’s API](https://developer.spotify.com/documentation/web-api/) that provide insight into the music itself, e.g. the \"acousticness\" of the song.  We will tackle a regression problem here, trying to predict the score of a review from several of the other columns in the dataset.\n",
    "\n",
    "## Part 1.1 - Feature Engineering with Feature Subsets\n",
    "\n",
    "In the first subsection of Part 1, We’re going to look at how running linear regression with various subsets of our features impacts our ability to predict score.\n",
    "\n",
    "In Part 1.1, Here we are going to train a separate linear regression model for a number of different feature subsets.  Specifically:\n",
    "\n",
    "- The list `feature_sets` below is a list of lists; each sublist is a different subset of features to build a model with. \n",
    "- All models should be trained on the dataset `part1_train.csv`. \n",
    "- For each of these trained models, you should evaluate the model’s predictions on the training dataset, as well as the provided test set, called `part1_test.csv`. The evaluation metric we will use is **root mean squared error**.  \n",
    "\n",
    "Our output file `part_1.1_results.csv` will have the following columns:\n",
    "- `feature_set` - a column describing the features of the model used. For feature sets with multiple features, combine them using an underscore (you can do this with the code `\"_\".join(feature_set)`)\n",
    "- `training_rmse` - a column that gives the RMSE of a linear regression model trained on this feature set on the training data\n",
    "- `test_rmse` - a column that gives the RMSE of a linear regression model trained on this feature set on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "waiting-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [['artist'],\n",
    " ['reviewauthor'],\n",
    " ['releaseyear'],\n",
    " ['recordlabel'],\n",
    " ['genre'],\n",
    " ['danceability'],\n",
    " ['energy'],\n",
    " ['key'],\n",
    " ['loudness'],\n",
    " ['speechiness'],\n",
    " ['acousticness'],\n",
    " ['instrumentalness'],\n",
    " ['liveness'],\n",
    " ['valence'],\n",
    " ['tempo'],\n",
    " ['danceability','energy','key','loudness','speechiness','acousticness',\n",
    "  'instrumentalness','liveness','valence','tempo'],\n",
    " ['artist', 'reviewauthor', 'releaseyear', 'recordlabel', 'genre'],\n",
    " ['artist', 'reviewauthor', 'releaseyear', 'recordlabel', 'genre', 'danceability', \n",
    "  'energy', 'key', 'loudness', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "  'liveness', 'valence', 'tempo']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caring-aluminum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_set</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artist</td>\n",
       "      <td>1.243393</td>\n",
       "      <td>1.243591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reviewauthor</td>\n",
       "      <td>1.243345</td>\n",
       "      <td>1.243498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>releaseyear</td>\n",
       "      <td>1.235994</td>\n",
       "      <td>1.232989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recordlabel</td>\n",
       "      <td>1.242969</td>\n",
       "      <td>1.244257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genre</td>\n",
       "      <td>1.242326</td>\n",
       "      <td>1.242353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>danceability</td>\n",
       "      <td>1.240362</td>\n",
       "      <td>1.241097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>energy</td>\n",
       "      <td>1.240900</td>\n",
       "      <td>1.239929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>key</td>\n",
       "      <td>1.243497</td>\n",
       "      <td>1.243823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>loudness</td>\n",
       "      <td>1.236968</td>\n",
       "      <td>1.237578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speechiness</td>\n",
       "      <td>1.243530</td>\n",
       "      <td>1.243566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acousticness</td>\n",
       "      <td>1.240370</td>\n",
       "      <td>1.240188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>1.238989</td>\n",
       "      <td>1.238840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>liveness</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>valence</td>\n",
       "      <td>1.242268</td>\n",
       "      <td>1.240970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tempo</td>\n",
       "      <td>1.243195</td>\n",
       "      <td>1.242322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>danceability_energy_key_loudness_speechiness_a...</td>\n",
       "      <td>1.233091</td>\n",
       "      <td>1.235554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>artist_reviewauthor_releaseyear_recordlabel_genre</td>\n",
       "      <td>1.233341</td>\n",
       "      <td>1.231714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>artist_reviewauthor_releaseyear_recordlabel_ge...</td>\n",
       "      <td>1.224337</td>\n",
       "      <td>1.224779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          feature_set  training_rmse  \\\n",
       "0                                              artist       1.243393   \n",
       "1                                        reviewauthor       1.243345   \n",
       "2                                         releaseyear       1.235994   \n",
       "3                                         recordlabel       1.242969   \n",
       "4                                               genre       1.242326   \n",
       "5                                        danceability       1.240362   \n",
       "6                                              energy       1.240900   \n",
       "7                                                 key       1.243497   \n",
       "8                                            loudness       1.236968   \n",
       "9                                         speechiness       1.243530   \n",
       "10                                       acousticness       1.240370   \n",
       "11                                   instrumentalness       1.238989   \n",
       "12                                           liveness       1.243534   \n",
       "13                                            valence       1.242268   \n",
       "14                                              tempo       1.243195   \n",
       "15  danceability_energy_key_loudness_speechiness_a...       1.233091   \n",
       "16  artist_reviewauthor_releaseyear_recordlabel_genre       1.233341   \n",
       "17  artist_reviewauthor_releaseyear_recordlabel_ge...       1.224337   \n",
       "\n",
       "    test_rmse  \n",
       "0    1.243591  \n",
       "1    1.243498  \n",
       "2    1.232989  \n",
       "3    1.244257  \n",
       "4    1.242353  \n",
       "5    1.241097  \n",
       "6    1.239929  \n",
       "7    1.243823  \n",
       "8    1.237578  \n",
       "9    1.243566  \n",
       "10   1.240188  \n",
       "11   1.238840  \n",
       "12   1.243558  \n",
       "13   1.240970  \n",
       "14   1.242322  \n",
       "15   1.235554  \n",
       "16   1.231714  \n",
       "17   1.224779  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Convenience things for you, note that releaseyear is continuous but is not a Spotify API variable\n",
    "CONTINUOUS_FEATURES = ['releaseyear', 'danceability', 'energy', 'key', 'loudness',\n",
    "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "       'valence', 'tempo']\n",
    "CATEGORICAL_FEATURES = ['artist', 'reviewauthor', 'recordlabel', 'genre']\n",
    "\n",
    "# Read in the data\n",
    "training_data = pd.read_csv(\"part1_train.csv\")\n",
    "test_data = pd.read_csv(\"part1_test.csv\")\n",
    "\n",
    "new_training_data = training_data\n",
    "new_test_data = test_data\n",
    "\n",
    "for feature in CATEGORICAL_FEATURES:\n",
    "    new_training_data[feature] = labelencoder.fit_transform(new_training_data[feature])\n",
    "    new_test_data[feature] = labelencoder.fit_transform(new_test_data[feature])\n",
    "\n",
    "result_data = []\n",
    "for feature_set in feature_sets:\n",
    "    X_train = new_training_data[feature_set]\n",
    "    y_train = new_training_data['score']    \n",
    "    X_test = new_test_data[feature_set]\n",
    "    y_test = new_test_data['score']\n",
    "    clf1 = LinearRegression(fit_intercept=True)\n",
    "    clf1.fit(X_train,y_train)\n",
    "    test_pred = clf1.predict(X_test)\n",
    "    train_pred = clf1.predict(X_train)\n",
    "    result_data.append([\"_\".join(feature_set), math.sqrt(mean_squared_error(y_train,train_pred)), math.sqrt(mean_squared_error(y_test,test_pred))])\n",
    "\n",
    "result = pd.DataFrame(result_data)\n",
    "result.columns = [\"feature_set\",\"training_rmse\",\"test_rmse\"]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0475dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"part_1.1_results.csv\",sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-mercy",
   "metadata": {},
   "source": [
    "## Part 1.2 - Feature Engineering with the LASSO\n",
    "\n",
    "In Part 1.2, We will be training an L1-regularized linear regression model, with an expanded feature set.  Specifically:\n",
    "\n",
    "1. Begin with the final feature set listed in `feature_sets` (i.e. your feature set, to begin this section, is `feature_sets[-1]`.\n",
    "2. One-hot encode your categorical variables, setting `drop=if_binary` and `sparse=False` in the function arguments. \n",
    "3. Scale all of your continuous features using the `StandardScaler`.\n",
    "4. Train an L1-regularized linear regression model using these features on the dataset `part1_train.csv`. You should use the [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) class in `sklearn`, it will do the cross-validation necessary to select the appropriate value for the regularizer for you!  Use 10-fold cross-validation to perform model selection (set the `LassoCV` parmaeter `cv` to 10), and set the `random_state` to 1. Do not change any of the other parameters to `LassoCV` (i.e. leave them at their defaults).\n",
    "5. Identify the best `alpha` value (the regularizer term, according to `sklearn`. In class, we refer to this as $\\lambda$!) in terms of average mean squared error according to the cross-validation.\n",
    "6. Finally, train a [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) model on the entire training dataset (`part1_train.csv`). We will use this to report the root mean squared error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "loose-width",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training</th>\n",
       "      <th>testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.122921</td>\n",
       "      <td>1.343646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      training   testing\n",
       "RMSE  1.122921  1.343646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_penalty</th>\n",
       "      <th>model</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.164865</td>\n",
       "      <td>1.249920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002683</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.193347</td>\n",
       "      <td>1.227617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007197</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.212013</td>\n",
       "      <td>1.224412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019307</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.226351</td>\n",
       "      <td>1.224815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051795</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.230498</td>\n",
       "      <td>1.229373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138950</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.372759</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.682696</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.196857</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.306977</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>51.794747</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>138.949549</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>372.759372</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>(ColumnTransformer(transformers=[('categorical...</td>\n",
       "      <td>1.243534</td>\n",
       "      <td>1.243558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     l1_penalty                                              model  \\\n",
       "0      0.001000  (ColumnTransformer(transformers=[('categorical...   \n",
       "1      0.002683  (ColumnTransformer(transformers=[('categorical...   \n",
       "2      0.007197  (ColumnTransformer(transformers=[('categorical...   \n",
       "3      0.019307  (ColumnTransformer(transformers=[('categorical...   \n",
       "4      0.051795  (ColumnTransformer(transformers=[('categorical...   \n",
       "5      0.138950  (ColumnTransformer(transformers=[('categorical...   \n",
       "6      0.372759  (ColumnTransformer(transformers=[('categorical...   \n",
       "7      1.000000  (ColumnTransformer(transformers=[('categorical...   \n",
       "8      2.682696  (ColumnTransformer(transformers=[('categorical...   \n",
       "9      7.196857  (ColumnTransformer(transformers=[('categorical...   \n",
       "10    19.306977  (ColumnTransformer(transformers=[('categorical...   \n",
       "11    51.794747  (ColumnTransformer(transformers=[('categorical...   \n",
       "12   138.949549  (ColumnTransformer(transformers=[('categorical...   \n",
       "13   372.759372  (ColumnTransformer(transformers=[('categorical...   \n",
       "14  1000.000000  (ColumnTransformer(transformers=[('categorical...   \n",
       "\n",
       "    train_rmse  test_rmse  \n",
       "0     1.164865   1.249920  \n",
       "1     1.193347   1.227617  \n",
       "2     1.212013   1.224412  \n",
       "3     1.226351   1.224815  \n",
       "4     1.230498   1.229373  \n",
       "5     1.243534   1.243558  \n",
       "6     1.243534   1.243558  \n",
       "7     1.243534   1.243558  \n",
       "8     1.243534   1.243558  \n",
       "9     1.243534   1.243558  \n",
       "10    1.243534   1.243558  \n",
       "11    1.243534   1.243558  \n",
       "12    1.243534   1.243558  \n",
       "13    1.243534   1.243558  \n",
       "14    1.243534   1.243558  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code for Part 1.2 here\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix,classification_report, precision_score, roc_auc_score\n",
    "\n",
    "# Do the CV to find alpha\n",
    "features = feature_sets[-1]\n",
    "X_train = training_data[features]\n",
    "y_train = training_data['score']    \n",
    "X_test = test_data[features]\n",
    "y_test = test_data['score']\n",
    "basic_pipeline = make_pipeline(\n",
    "        ColumnTransformer([('numerical', StandardScaler(), CONTINUOUS_FEATURES),\n",
    "                           (\"categorical\", OneHotEncoder(drop =\"if_binary\",sparse=False),CATEGORICAL_FEATURES)]),\n",
    "    )\n",
    "\n",
    "clf1 = LassoCV(cv = 10, random_state = 1)\n",
    "pipe1 = Pipeline([(\"pipe\",basic_pipeline),\n",
    "                  ('clf1', clf1)])\n",
    "pipe1.fit(X_train,y_train)\n",
    "y_pred_test =  pipe1.predict(X_test)\n",
    "y_pred_train = pipe1.predict(X_train)\n",
    "\n",
    "rmse_train = math.sqrt(mean_squared_error(y_train,y_pred_train))\n",
    "rmse_test = math.sqrt(mean_squared_error(y_test,y_pred_test))\n",
    "\n",
    "                    \n",
    "evaluation_matrix_base_training = {\n",
    "    \"training\" : [rmse_train],\n",
    "    \"testing\": [rmse_test]\n",
    "}\n",
    "    \n",
    "\n",
    "eva_base_train = pd.DataFrame(data = evaluation_matrix_base_training, index = ['RMSE'])\n",
    "display(eva_base_train)\n",
    "\n",
    "\n",
    "# Retrain the model\n",
    "l1_penalties = np.logspace(-3, 3, num = 15) # TODO: make the list of lambda values\n",
    "lasso_output = []\n",
    "lasso_data_train = training_data[features + [\"score\"]].dropna()\n",
    "lasso_data_test = test_data[features+[\"score\"]].dropna()\n",
    "for l1_penalty in l1_penalties:\n",
    "    regression_pipeline = make_pipeline(ColumnTransformer([\n",
    "                           (\"categorical\", OneHotEncoder(drop =\"if_binary\",sparse=False),CATEGORICAL_FEATURES),\n",
    "                           (\"scale\",StandardScaler(),CONTINUOUS_FEATURES)\n",
    "                          ]),\n",
    "                          Lasso(alpha=l1_penalty, random_state=1)\n",
    "                         ) \n",
    "    regression_pipeline.fit(lasso_data_train,lasso_data_train.score)\n",
    "\n",
    "    train_rmse = np.sqrt(mean_squared_error(lasso_data_train.score, \n",
    "                                            regression_pipeline.predict(lasso_data_train)))\n",
    "    test_rmse = np.sqrt(mean_squared_error(lasso_data_test.score, \n",
    "                                            regression_pipeline.predict(lasso_data_test)))\n",
    "    # We maintain a list of dictionaries containing our results\n",
    "    lasso_output.append({'l1_penalty': l1_penalty,'model': regression_pipeline,'train_rmse': train_rmse,'test_rmse': test_rmse})\n",
    "    \n",
    "lasso_output = pd.DataFrame(lasso_output)\n",
    "display(lasso_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af4ddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2308278386434948"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lasso_output[\"train_rmse\"].sum())/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "formal-stable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-91657dc7-6302-46db-8000-9f99000c31e9 {color: black;background-color: white;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 pre{padding: 0;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-toggleable {background-color: white;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-item {z-index: 1;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-parallel-item:only-child::after {width: 0;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-91657dc7-6302-46db-8000-9f99000c31e9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-91657dc7-6302-46db-8000-9f99000c31e9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;artist&#x27;, &#x27;reviewauthor&#x27;,\n",
       "                                                   &#x27;recordlabel&#x27;, &#x27;genre&#x27;]),\n",
       "                                                 (&#x27;scale&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;releaseyear&#x27;,\n",
       "                                                   &#x27;danceability&#x27;, &#x27;energy&#x27;,\n",
       "                                                   &#x27;key&#x27;, &#x27;loudness&#x27;,\n",
       "                                                   &#x27;speechiness&#x27;,\n",
       "                                                   &#x27;acousticness&#x27;,\n",
       "                                                   &#x27;instrumentalness&#x27;,\n",
       "                                                   &#x27;liveness&#x27;, &#x27;valence&#x27;,\n",
       "                                                   &#x27;tempo&#x27;])])),\n",
       "                (&#x27;lasso&#x27;, Lasso(alpha=0.0071968567300115215, random_state=1))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5f214aab-389a-4bee-a569-23bce81133a4\" type=\"checkbox\" ><label for=\"5f214aab-389a-4bee-a569-23bce81133a4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;artist&#x27;, &#x27;reviewauthor&#x27;,\n",
       "                                                   &#x27;recordlabel&#x27;, &#x27;genre&#x27;]),\n",
       "                                                 (&#x27;scale&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;releaseyear&#x27;,\n",
       "                                                   &#x27;danceability&#x27;, &#x27;energy&#x27;,\n",
       "                                                   &#x27;key&#x27;, &#x27;loudness&#x27;,\n",
       "                                                   &#x27;speechiness&#x27;,\n",
       "                                                   &#x27;acousticness&#x27;,\n",
       "                                                   &#x27;instrumentalness&#x27;,\n",
       "                                                   &#x27;liveness&#x27;, &#x27;valence&#x27;,\n",
       "                                                   &#x27;tempo&#x27;])])),\n",
       "                (&#x27;lasso&#x27;, Lasso(alpha=0.0071968567300115215, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2d566f08-4b66-49e4-bf07-6109e4c2fc1e\" type=\"checkbox\" ><label for=\"2d566f08-4b66-49e4-bf07-6109e4c2fc1e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;if_binary&#x27;, sparse=False),\n",
       "                                 [&#x27;artist&#x27;, &#x27;reviewauthor&#x27;, &#x27;recordlabel&#x27;,\n",
       "                                  &#x27;genre&#x27;]),\n",
       "                                (&#x27;scale&#x27;, StandardScaler(),\n",
       "                                 [&#x27;releaseyear&#x27;, &#x27;danceability&#x27;, &#x27;energy&#x27;,\n",
       "                                  &#x27;key&#x27;, &#x27;loudness&#x27;, &#x27;speechiness&#x27;,\n",
       "                                  &#x27;acousticness&#x27;, &#x27;instrumentalness&#x27;,\n",
       "                                  &#x27;liveness&#x27;, &#x27;valence&#x27;, &#x27;tempo&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d3510bb4-0447-413c-a5b0-dfa8c662e543\" type=\"checkbox\" ><label for=\"d3510bb4-0447-413c-a5b0-dfa8c662e543\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;artist&#x27;, &#x27;reviewauthor&#x27;, &#x27;recordlabel&#x27;, &#x27;genre&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"95166263-618f-49f6-8e0a-0f0011ccd55e\" type=\"checkbox\" ><label for=\"95166263-618f-49f6-8e0a-0f0011ccd55e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1a034fc3-44b8-4258-b578-63f149012c07\" type=\"checkbox\" ><label for=\"1a034fc3-44b8-4258-b578-63f149012c07\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scale</label><div class=\"sk-toggleable__content\"><pre>[&#x27;releaseyear&#x27;, &#x27;danceability&#x27;, &#x27;energy&#x27;, &#x27;key&#x27;, &#x27;loudness&#x27;, &#x27;speechiness&#x27;, &#x27;acousticness&#x27;, &#x27;instrumentalness&#x27;, &#x27;liveness&#x27;, &#x27;valence&#x27;, &#x27;tempo&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9fd85a69-40f5-4946-8043-81b0e623d3f3\" type=\"checkbox\" ><label for=\"9fd85a69-40f5-4946-8043-81b0e623d3f3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a954052a-cfe0-4bc4-97fb-166095f8f70e\" type=\"checkbox\" ><label for=\"a954052a-cfe0-4bc4-97fb-166095f8f70e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.0071968567300115215, random_state=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  OneHotEncoder(drop='if_binary',\n",
       "                                                                sparse=False),\n",
       "                                                  ['artist', 'reviewauthor',\n",
       "                                                   'recordlabel', 'genre']),\n",
       "                                                 ('scale', StandardScaler(),\n",
       "                                                  ['releaseyear',\n",
       "                                                   'danceability', 'energy',\n",
       "                                                   'key', 'loudness',\n",
       "                                                   'speechiness',\n",
       "                                                   'acousticness',\n",
       "                                                   'instrumentalness',\n",
       "                                                   'liveness', 'valence',\n",
       "                                                   'tempo'])])),\n",
       "                ('lasso', Lasso(alpha=0.0071968567300115215, random_state=1))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config \n",
    "from sklearn.utils import estimator_html_repr \n",
    "from IPython.core.display import display, HTML \n",
    "set_config(display='diagram')\n",
    "mod = lasso_output.model.iloc[2]\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc30580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>categorical__recordlabel_316</td>\n",
       "      <td>0.196678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>categorical__genre_1</td>\n",
       "      <td>0.121404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>categorical__reviewauthor_181</td>\n",
       "      <td>0.086074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>categorical__reviewauthor_136</td>\n",
       "      <td>0.085880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>scale__instrumentalness</td>\n",
       "      <td>0.062686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>scale__releaseyear</td>\n",
       "      <td>-0.129545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>categorical__artist_63</td>\n",
       "      <td>-0.131319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>categorical__reviewauthor_195</td>\n",
       "      <td>-0.171756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>categorical__reviewauthor_2</td>\n",
       "      <td>-0.189233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>categorical__reviewauthor_81</td>\n",
       "      <td>-0.303939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          features     coefs\n",
       "666   categorical__recordlabel_316  0.196678\n",
       "670           categorical__genre_1  0.121404\n",
       "287  categorical__reviewauthor_181  0.086074\n",
       "242  categorical__reviewauthor_136  0.085880\n",
       "687        scale__instrumentalness  0.062686\n",
       "..                             ...       ...\n",
       "680             scale__releaseyear -0.129545\n",
       "63          categorical__artist_63 -0.131319\n",
       "301  categorical__reviewauthor_195 -0.171756\n",
       "108    categorical__reviewauthor_2 -0.189233\n",
       "187   categorical__reviewauthor_81 -0.303939\n",
       "\n",
       "[691 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_results = pd.DataFrame({\"features\" : mod[-2].get_feature_names_out(),\n",
    "              \"coefs\" : mod[-1].coef_\n",
    "             })\n",
    "lasso_results.sort_values(\"coefs\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84840e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non zero coefficients are 21\n",
      "Percentage of total number of non zero coefficients are 3.04\n"
     ]
    }
   ],
   "source": [
    "non_zeros_count = sum(lasso_results[\"coefs\"][lasso_results[\"coefs\"] != 0].value_counts())\n",
    "total_count = sum(lasso_results[\"coefs\"].value_counts())\n",
    "print(f'Total number of non zero coefficients are',non_zeros_count)\n",
    "print(f'Percentage of total number of non zero coefficients are',round((non_zeros_count/total_count),4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63749914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>categorical__reviewauthor_181</td>\n",
       "      <td>0.086074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>categorical__reviewauthor_136</td>\n",
       "      <td>0.085880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>categorical__reviewauthor_167</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>categorical__reviewauthor_155</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>categorical__reviewauthor_156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>categorical__reviewauthor_243</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>categorical__reviewauthor_130</td>\n",
       "      <td>-0.121298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>categorical__reviewauthor_195</td>\n",
       "      <td>-0.171756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>categorical__reviewauthor_2</td>\n",
       "      <td>-0.189233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>categorical__reviewauthor_81</td>\n",
       "      <td>-0.303939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          features     coefs\n",
       "287  categorical__reviewauthor_181  0.086074\n",
       "242  categorical__reviewauthor_136  0.085880\n",
       "273  categorical__reviewauthor_167  0.000000\n",
       "261  categorical__reviewauthor_155  0.000000\n",
       "262  categorical__reviewauthor_156  0.000000\n",
       "..                             ...       ...\n",
       "349  categorical__reviewauthor_243  0.000000\n",
       "236  categorical__reviewauthor_130 -0.121298\n",
       "301  categorical__reviewauthor_195 -0.171756\n",
       "108    categorical__reviewauthor_2 -0.189233\n",
       "187   categorical__reviewauthor_81 -0.303939\n",
       "\n",
       "[244 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_results[lasso_results[\"features\"].str.contains('reviewauthor', na=False)].sort_values(\"coefs\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c2160e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>categorical__genre_1</td>\n",
       "      <td>0.121404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>categorical__genre_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>categorical__genre_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>categorical__genre_4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>categorical__genre_5</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>categorical__genre_6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>categorical__genre_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>categorical__genre_9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>categorical__genre_8</td>\n",
       "      <td>-0.037467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>categorical__genre_0</td>\n",
       "      <td>-0.096707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>categorical__genre_10</td>\n",
       "      <td>-0.118597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features     coefs\n",
       "670   categorical__genre_1  0.121404\n",
       "671   categorical__genre_2  0.000000\n",
       "672   categorical__genre_3  0.000000\n",
       "673   categorical__genre_4  0.000000\n",
       "674   categorical__genre_5 -0.000000\n",
       "675   categorical__genre_6  0.000000\n",
       "676   categorical__genre_7  0.000000\n",
       "678   categorical__genre_9  0.000000\n",
       "677   categorical__genre_8 -0.037467\n",
       "669   categorical__genre_0 -0.096707\n",
       "679  categorical__genre_10 -0.118597"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_results[lasso_results[\"features\"].str.contains('genre', na=False)].sort_values(\"coefs\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "602f3fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>categorical__artist_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>categorical__artist_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>categorical__artist_78</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>categorical__artist_77</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>categorical__artist_76</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>categorical__artist_31</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>categorical__artist_30</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>categorical__artist_29</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>categorical__artist_105</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>categorical__artist_63</td>\n",
       "      <td>-0.131319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    features     coefs\n",
       "0      categorical__artist_0  0.000000\n",
       "1      categorical__artist_1  0.000000\n",
       "78    categorical__artist_78  0.000000\n",
       "77    categorical__artist_77 -0.000000\n",
       "76    categorical__artist_76  0.000000\n",
       "..                       ...       ...\n",
       "31    categorical__artist_31  0.000000\n",
       "30    categorical__artist_30 -0.000000\n",
       "29    categorical__artist_29 -0.000000\n",
       "105  categorical__artist_105  0.000000\n",
       "63    categorical__artist_63 -0.131319\n",
       "\n",
       "[106 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_results[lasso_results[\"features\"].str.contains('artist', na=False)].sort_values(\"coefs\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-lesbian",
   "metadata": {},
   "source": [
    "# Part 1.4 - \"Manual\" Cross-Validation + Holdout for Model Selection and Evaluation\n",
    "\n",
    "We will finally use cross validation for both algorithm and model selection, with a hold-out test set for a final evaluation. We will use **5-fold cross validation** to identify the best parameters and hyperparameters for a set of models. We will then take our final models and use a final hold-out test set (the same one as above) to estimate the generalization error of the models.\n",
    "\n",
    "Specifically, We will be training and evaluating the following models, one for each of the specified hyper parameters sets:\n",
    "\n",
    "- `Decision Tree regression` - All combinations of a `max_depth` of 5, 10, or 20, and a `criterion` of `\"squared error\"` or `\"absolute error\"`. Use the [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor).\n",
    "- Ridge regression - Use the following choices of L2 penalty: $[10^{-5}, 10^{-4}, ..., 10^4, 10^5]$. In Python, you can create a list of these numbers using `np.logspace(-5, 5, 11)`. Use the [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) class from sklearn to train a Ridge Regression model. The parameters you need to pass when constructing the Ridge model are `alpha`, which lets you specify what you want the L2 penalty to be, and `random_state=0` to avoid randomness.\n",
    "- kNN regression - Values of `n_neighbors` of 1, 5, 10, and 15. Use the [KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) class.\n",
    "\n",
    "Our output file `part_1.4_results.csv`should have the following columns:\n",
    "- `model_name` - The name of the model, one of `DTR` (Decision Tree Regression), `Ridge`, or `KNN`.\n",
    "- `hyperparameter_setting` - a column describing the hyperparameters of the model. For models with multiple hyperparameters, combine them using an underscore (you can do this with the code `\"_\".join(hyperparameters)`).\n",
    "- `mean_training_rmse` - a column that gives the mean RMSE on the k-fold training data. You should take the average of the model’s errors on the different folds, using root mean squared error again as your evaluation metric.\n",
    "- `sd_training_rmse` - a column that gives the standard deviation RMSE on the k-fold training data.\n",
    "- `test_rmse` - a column that gives the RMSE of a linear regression model trained on this feature set on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9b3da35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>hyperparameter_setting</th>\n",
       "      <th>mean_training_rmse</th>\n",
       "      <th>sd_training_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTR</td>\n",
       "      <td>5_squared_error</td>\n",
       "      <td>1.185240</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>1.209052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTR</td>\n",
       "      <td>5_absolute_error</td>\n",
       "      <td>1.207012</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>1.229086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTR</td>\n",
       "      <td>10_squared_error</td>\n",
       "      <td>1.107777</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>1.250543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTR</td>\n",
       "      <td>10_absolute_error</td>\n",
       "      <td>1.148851</td>\n",
       "      <td>0.011303</td>\n",
       "      <td>1.264720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTR</td>\n",
       "      <td>20_squared_error</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.019125</td>\n",
       "      <td>1.348417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTR</td>\n",
       "      <td>20_absolute_error</td>\n",
       "      <td>0.994747</td>\n",
       "      <td>0.032185</td>\n",
       "      <td>1.340303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504337</td>\n",
       "      <td>0.490956</td>\n",
       "      <td>1.600402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.586845</td>\n",
       "      <td>0.420960</td>\n",
       "      <td>1.416636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.693795</td>\n",
       "      <td>0.409158</td>\n",
       "      <td>1.274647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.774806</td>\n",
       "      <td>0.400271</td>\n",
       "      <td>1.226887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.830618</td>\n",
       "      <td>0.386141</td>\n",
       "      <td>1.180388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.870485</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>1.180387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.900384</td>\n",
       "      <td>0.355603</td>\n",
       "      <td>1.180381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.923639</td>\n",
       "      <td>0.341673</td>\n",
       "      <td>1.180317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.942245</td>\n",
       "      <td>0.328924</td>\n",
       "      <td>1.179707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957514</td>\n",
       "      <td>0.317325</td>\n",
       "      <td>1.175053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.971251</td>\n",
       "      <td>0.307224</td>\n",
       "      <td>1.165559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.986336</td>\n",
       "      <td>0.299770</td>\n",
       "      <td>1.182385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.002310</td>\n",
       "      <td>0.294558</td>\n",
       "      <td>1.212416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.017486</td>\n",
       "      <td>0.290187</td>\n",
       "      <td>1.228917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.031621</td>\n",
       "      <td>0.286265</td>\n",
       "      <td>1.241454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model_name hyperparameter_setting  mean_training_rmse  sd_training_rmse  \\\n",
       "0         DTR        5_squared_error            1.185240          0.006366   \n",
       "1         DTR       5_absolute_error            1.207012          0.007595   \n",
       "2         DTR       10_squared_error            1.107777          0.013955   \n",
       "3         DTR      10_absolute_error            1.148851          0.011303   \n",
       "4         DTR       20_squared_error            0.947981          0.019125   \n",
       "5         DTR      20_absolute_error            0.994747          0.032185   \n",
       "6         KNN                      1            0.504337          0.490956   \n",
       "7         KNN                      2            0.586845          0.420960   \n",
       "8         KNN                      5            0.693795          0.409158   \n",
       "9         KNN                     10            0.774806          0.400271   \n",
       "10      Ridge                  1e-05            0.830618          0.386141   \n",
       "11      Ridge                 0.0001            0.870485          0.370612   \n",
       "12      Ridge                  0.001            0.900384          0.355603   \n",
       "13      Ridge                   0.01            0.923639          0.341673   \n",
       "14      Ridge                    0.1            0.942245          0.328924   \n",
       "15      Ridge                    1.0            0.957514          0.317325   \n",
       "16      Ridge                   10.0            0.971251          0.307224   \n",
       "17      Ridge                  100.0            0.986336          0.299770   \n",
       "18      Ridge                 1000.0            1.002310          0.294558   \n",
       "19      Ridge                10000.0            1.017486          0.290187   \n",
       "20      Ridge               100000.0            1.031621          0.286265   \n",
       "\n",
       "    test_rmse  \n",
       "0    1.209052  \n",
       "1    1.229086  \n",
       "2    1.250543  \n",
       "3    1.264720  \n",
       "4    1.348417  \n",
       "5    1.340303  \n",
       "6    1.600402  \n",
       "7    1.416636  \n",
       "8    1.274647  \n",
       "9    1.226887  \n",
       "10   1.180388  \n",
       "11   1.180387  \n",
       "12   1.180381  \n",
       "13   1.180317  \n",
       "14   1.179707  \n",
       "15   1.175053  \n",
       "16   1.165559  \n",
       "17   1.182385  \n",
       "18   1.212416  \n",
       "19   1.228917  \n",
       "20   1.241454  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix,classification_report, precision_score, roc_auc_score\n",
    "\n",
    "fold0_data = pd.read_csv(\"/Users/aparna_kamal/Downloads/assignment2/1.2_fold0.csv\").dropna()\n",
    "fold1_data = pd.read_csv(\"/Users/aparna_kamal/Downloads/assignment2/1.2_fold1.csv\").dropna()\n",
    "fold2_data = pd.read_csv(\"/Users/aparna_kamal/Downloads/assignment2/1.2_fold2.csv\").dropna()\n",
    "fold3_data = pd.read_csv(\"/Users/aparna_kamal/Downloads/assignment2/1.2_fold3.csv\").dropna()\n",
    "fold4_data = pd.read_csv(\"/Users/aparna_kamal/Downloads/assignment2/1.2_fold4.csv\").dropna()\n",
    "\n",
    "\n",
    "fold1234_train = pd.concat([fold1_data,fold2_data,fold3_data,fold4_data])\n",
    "fold0234_train = pd.concat([fold0_data,fold2_data,fold3_data,fold4_data])\n",
    "fold0134_train = pd.concat([fold0_data,fold1_data,fold3_data,fold4_data])\n",
    "fold0123_train = pd.concat([fold1_data,fold2_data,fold3_data,fold0_data])\n",
    "fold0124_train = pd.concat([fold1_data,fold2_data,fold0_data,fold0_data])\n",
    "\n",
    "training_entire_set =[]\n",
    "test_entire_set = []\n",
    "training_entire_set.append(fold1234_train)\n",
    "test_entire_set.append(fold0_data)\n",
    "training_entire_set.append(fold0234_train)\n",
    "test_entire_set.append(fold1_data)\n",
    "training_entire_set.append(fold0134_train)\n",
    "test_entire_set.append(fold2_data)\n",
    "training_entire_set.append(fold0124_train)\n",
    "test_entire_set.append(fold3_data)\n",
    "training_entire_set.append(fold0123_train)\n",
    "test_entire_set.append(fold4_data)\n",
    "\n",
    "basic_pipeline = make_pipeline(\n",
    "        ColumnTransformer([('numerical', StandardScaler(), CONTINUOUS_FEATURES),\n",
    "                           (\"categorical\", OneHotEncoder(drop =\"if_binary\",sparse=False),CATEGORICAL_FEATURES)]),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# clf1 = DecisionTreeRegressor(random_state=1)\n",
    "# clf2 = Ridge(random_state = 0)\n",
    "# clf3 = KNeighborsRegressor()\n",
    "\n",
    "DT_CRITERIA = [\"squared_error\",\"absolute_error\"]\n",
    "DT_MAX_DEPTH = [5,10,20]\n",
    "\n",
    "KNN_NEIGHBOR = [1,2,5,10]\n",
    "RIDGE_PARAM = np.logspace(-5, 5, num = 11)\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in range(0,len(DT_MAX_DEPTH)):\n",
    "    for j in range(0,len(DT_CRITERIA)):\n",
    "        rmse_train=0\n",
    "        rmse_test = 0\n",
    "        rmse_sd = []\n",
    "        for k in range(0,5):\n",
    "            X_train = training_entire_set[k][features]\n",
    "            y_train = training_entire_set[k]['score']    \n",
    "            X_test = test_entire_set[k][features]\n",
    "            y_test = test_entire_set[k]['score']\n",
    "            clf1 =  DecisionTreeRegressor(random_state = 1, criterion = DT_CRITERIA[j], max_depth=DT_MAX_DEPTH[i])\n",
    "            pipe_DT = Pipeline([(\"pipe\",basic_pipeline),\n",
    "                        ('clf1', clf1)])\n",
    "            pipe_DT.fit(X_train,y_train)\n",
    "            y_pred_train = pipe_DT.predict(X_train)\n",
    "            y_pred_test = pipe_DT.predict(X_test)\n",
    "            rmse_train = math.sqrt(mean_squared_error(y_train,y_pred_train))\n",
    "            rmse_sd.append(rmse_train)\n",
    "            rmse_test = rmse_test+math.sqrt(mean_squared_error(y_test,y_pred_test))\n",
    "        rmse_train_mean = np.mean(rmse_sd)\n",
    "        rmse_sd_train = np.std(rmse_sd)\n",
    "        rmse_test = rmse_test/5\n",
    "        result.append([\"DTR\",str(DT_MAX_DEPTH[i])+\"_\"+DT_CRITERIA[j],rmse_train_mean,rmse_sd_train,rmse_test])\n",
    "            \n",
    "        \n",
    "        \n",
    "### KNN #####\n",
    "for j in range(0,len(KNN_NEIGHBOR)):\n",
    "    rmse_train=0\n",
    "    rmse_test = 0\n",
    "    for i in range(0,5):\n",
    "        X_train = training_entire_set[i][features]\n",
    "        y_train = training_entire_set[i]['score']    \n",
    "        X_test = test_entire_set[i][features]\n",
    "        y_test = test_entire_set[i]['score']\n",
    "        clf3 = KNeighborsRegressor(n_neighbors=KNN_NEIGHBOR[j])\n",
    "        pipe_KNN = Pipeline([(\"pipe\",basic_pipeline),\n",
    "                    ('clf3', clf3)])\n",
    "        pipe_KNN.fit(X_train,y_train)\n",
    "        y_pred_train = pipe_KNN.predict(X_train)\n",
    "        y_pred_test = pipe_KNN.predict(X_test)\n",
    "        rmse_train = math.sqrt(mean_squared_error(y_train,y_pred_train))\n",
    "        rmse_sd.append(rmse_train)\n",
    "        rmse_test = rmse_test+math.sqrt(mean_squared_error(y_test,y_pred_test))\n",
    "    rmse_train_mean = np.mean(rmse_sd)\n",
    "    rmse_sd_train = np.std(rmse_sd)\n",
    "    rmse_test = rmse_test/5\n",
    "    result.append([\"KNN\",str(KNN_NEIGHBOR[j]),rmse_train_mean,rmse_sd_train,rmse_test])\n",
    "        \n",
    "\n",
    "##### RIDGE #####\n",
    "RIDGE={}\n",
    "for j in range(0,len(RIDGE_PARAM)):\n",
    "    rmse_train=0\n",
    "    rmse_test = 0\n",
    "    for i in range(0,5):\n",
    "        X_train = training_entire_set[i][features]\n",
    "        y_train = training_entire_set[i]['score']    \n",
    "        X_test = test_entire_set[i][features]\n",
    "        y_test = test_entire_set[i]['score']\n",
    "        clf2 = Ridge(alpha = RIDGE_PARAM[j])\n",
    "        pipe_RR = Pipeline([(\"pipe\",basic_pipeline),\n",
    "                  ('clf2', clf2)])\n",
    "        pipe_RR.fit(X_train,y_train)\n",
    "        y_pred_train = pipe_RR.predict(X_train)\n",
    "        y_pred_test = pipe_RR.predict(X_test)\n",
    "        rmse_train = math.sqrt(mean_squared_error(y_train,y_pred_train))\n",
    "        rmse_sd.append(rmse_train)\n",
    "        rmse_test = rmse_test+math.sqrt(mean_squared_error(y_test,y_pred_test))\n",
    "    rmse_train_mean = np.mean(rmse_sd)\n",
    "    rmse_sd_train = np.std(rmse_sd)\n",
    "    rmse_test = rmse_test/5\n",
    "    result.append(['Ridge',str(RIDGE_PARAM[j]),rmse_train_mean,rmse_sd_train,rmse_test])\n",
    "\n",
    "output = pd.DataFrame(result)\n",
    "output.columns = [\"Model_name\",\"hyperparameter_setting\",\"mean_training_rmse\",\"sd_training_rmse\",\"test_rmse\"]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23a56470",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"part_1.4_results.csv\",sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-viking",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "Here, we're going to perform optimization of one of the classification models - logistic regression. As a reminder...\n",
    "\n",
    "The loss function of logistic regression (also known as the logistic-loss or log-loss) is given by:\n",
    "\\begin{equation}\n",
    "  J({\\bf w}) = \\frac{1}{n}\\sum_{i=1}^n \\log{(1 + \\exp{(-y_i{\\bf w}^\\top{\\bf x}_i}))}\n",
    "  \\label{eqn:logloss}\n",
    "\\end{equation}\n",
    "\n",
    "The gradient for this loss function, as derived in class, is:\n",
    "\\begin{equation}\n",
    "  \\nabla J({\\bf w}) = -\\frac{1}{n}\\sum_{i=1}^n \\frac{y_i}{1 + \\exp{(y_i{\\bf w}^\\top{\\bf x}_i)}}{\\bf x}_i\n",
    "  \\label{eqn:loglossgradient}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The Hessian for the loss function is given by:\n",
    "\\begin{equation}\n",
    "  {\\bf H}({\\bf w}) = \\frac{1}{n} \\sum_{i=1}^n \\frac{\\exp{(y_i{\\bf w}^\\top{\\bf x}_i)}}{(1 + \\exp{(y_i{\\bf w}^\\top{\\bf x}_i)})^2}{\\bf x}_i{\\bf x}_i^\\top\n",
    "  \\label{eqn:loglosshessian}\n",
    "\\end{equation}\n",
    "\n",
    "## Part 2.1 - Logistic Regression with Gradient Descent\n",
    "\n",
    "In Part 2.1 we will implement logistic regression with gradient descent. \n",
    "\n",
    "1. `logistic_objective` - compute the logistic loss for the given data set (see equation above)\n",
    "2. `logistic_gradient` - compute the gradient vector of logistic loss for the given data set (see equation above)\n",
    "3. `run_gradient_descent` - run the gradient descent algorithm, given these two functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "standard-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_gradient(w, X, y):\n",
    "\n",
    "    # compute the gradient of the log-loss error (vector) with respect\n",
    "    # to w (vector) for the given data X and y  \n",
    "    #\n",
    "    # Inputs:\n",
    "    # w = d x 1\n",
    "    # X = N x d\n",
    "    # y = N x 1\n",
    "    # Output:\n",
    "    # error = d length gradient vector (not a d x 1 matrix)\n",
    "\n",
    "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
    "    if len(w.shape) == 1:\n",
    "        w = w[:,np.newaxis]\n",
    "    gradient = 0\n",
    "    l = 0\n",
    "    for i in range(0,len(X)):\n",
    "        yi=y[i]\n",
    "        xi=X[i]\n",
    "        wt=np.transpose(w)\n",
    "        l = l + (y[i]/(1+np.exp(np.dot(np.dot(-yi,wt),xi))))*(X[i])\n",
    "    return l/(len(X))\n",
    "\n",
    "def logistic_objective(w, X, y):\n",
    "\n",
    "    # compute log-loss error (scalar) with respect\n",
    "    # to w (vector) for the given data X and y                               \n",
    "    # Inputs:\n",
    "    # w = d x 1\n",
    "    # X = N x d\n",
    "    # y = N x 1\n",
    "    # Output:\n",
    "    # error = scalar\n",
    "    \n",
    "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
    "    if len(w.shape) == 1:\n",
    "        w = w[:,np.newaxis]\n",
    "    s=0\n",
    "    for i in range(1,len(X)):\n",
    "        yi=y[i]\n",
    "        xi=X[i]\n",
    "        wt=np.transpose(w)\n",
    "        s = s + np.log(1+np.exp(np.dot(np.dot(-yi,wt),xi)))\n",
    "    error = s/len(X)\n",
    "    return error\n",
    "\n",
    "def run_gradient_descent(X,y):\n",
    "    old_w = np.array([-1]*X.shape[1])\n",
    "    # change this value! This is an unreasonable step size\n",
    "    step_size = 0.0000005\n",
    "    new_w =old_w - 1\n",
    "    \n",
    "    while ((new_w-old_w)**2).sum() > .0000000001:\n",
    "        #IMPLEMENT THIS!\n",
    "        old_w=new_w\n",
    "        dw = logistic_gradient(new_w, X, y)\n",
    "        new_w=old_w-(step_size*dw)\n",
    "    return new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crude-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, bernoulli\n",
    "import functools\n",
    "draw_binary = functools.partial(np.random.binomial,n=1)\n",
    "\n",
    "## Simulated data to test your method\n",
    "DATA_SIZE = 10000\n",
    "x1 = bernoulli(.5).rvs(DATA_SIZE)\n",
    "x2 = np.floor(uniform(18,60).rvs(DATA_SIZE))\n",
    "true_w = [-9, 3.5, 0.2]\n",
    "xb = true_w[0] + true_w[1]*x1 + true_w[2]*x2\n",
    "p = 1/(1 + np.exp(-xb))\n",
    "y = np.array([1 if draw_binary(p=v) else -1 for v in p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "noted-newton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.48327258,  3.31959859,  0.18859071]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# notice that logistic regression as implemented in sklearn does not get the exact results either!\n",
    "# so you shouldn't worry if you're a bit off\n",
    "X = np.hstack([np.ones((len(xb),1)), x1[:,np.newaxis], x2[:,np.newaxis]])\n",
    "model = LogisticRegression(solver='liblinear', random_state=0,fit_intercept=False)\n",
    "model.fit(X,y).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "american-locking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.699995258300001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how we will test your results\n",
    "gd_result = run_gradient_descent(X,y)\n",
    "# is your result relatively close to the truth?\n",
    "np.abs(true_w-gd_result).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-toddler",
   "metadata": {},
   "source": [
    "## Part 2.2 - Optimization with Newton-Raphson \n",
    "\n",
    "In Part 2.2, we are going to use the Newton-Raphson method to optimize the same logistic regression model. To do so, we will need to 1) implement the `logistic_hessian` function to compute the Hessian matrix of logistic loss for the given data set, and 2) use `scipy`'s `optimize` function to perform the optimization, rather than writing a function by hand to do so.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conscious-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_hessian(w, X, y):\n",
    "\n",
    "    # compute the Hessian of the log-loss error (matrix) with respect\n",
    "    # to w (vector) for the given data X and y                               \n",
    "    #\n",
    "    # Inputs:\n",
    "    # w = d x 1\n",
    "    # X = N x d\n",
    "    # y = N x 1\n",
    "    # Output:\n",
    "    # Hessian = d x d matrix\n",
    "    \n",
    "    print(w.shape)\n",
    "    if len(w.shape) == 1:\n",
    "        w = w[:,np.newaxis]\n",
    "    print(w.shape)\n",
    "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
    "    hessian = np.zeros((X.shape[1],X.shape[1]))\n",
    "    for i in range(0,len(X)):\n",
    "        wt=np.transpose(w)\n",
    "        num = np.exp(np.dot(np.dot(y[i],wt),X[i]))\n",
    "        den = (1+np.exp(np.dot(np.dot(y[i],wt),X[i])))\n",
    "        den = np.dot(den,den)\n",
    "        hessian = hessian + np.dot(np.dot((num/den),(X[i])),np.transpose(X[i]))\n",
    "    hessian = hessian/len(X)\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bored-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def run_newton_raphson(X,y):\n",
    "    args = (X,y[:,np.newaxis])\n",
    "    opts = {'maxiter' : 50}    # Preferred value.    \n",
    "    w_init = np.zeros((X.shape[1]))\n",
    "    print(w_init.shape)\n",
    "    # note: this is almost what you need, you just need to figure out what arguments are necessary here!\n",
    "    soln = minimize(fun=logistic_objective,\n",
    "                    x0=w_init,\n",
    "                    jac=logistic_gradient,\n",
    "                    hess=logistic_hessian,\n",
    "                    args=args,\n",
    "                    method='Newton-CG',\n",
    "                    options=opts)\n",
    "\n",
    "    w = np.transpose(np.array(soln.x))\n",
    "    w = w[:,np.newaxis]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "liable-station",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3,)\n",
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_newton_raphson(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
